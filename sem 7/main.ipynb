{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.6.0-cp313-none-macosx_11_0_arm64.whl.metadata (28 kB)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.21.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (6.1 kB)\n",
      "Collecting onnx\n",
      "  Downloading onnx-1.17.0.tar.gz (12.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting onnxruntime\n",
      "  Downloading onnxruntime-1.20.1-cp313-cp313-macosx_13_0_universal2.whl.metadata (4.5 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Using cached filelock-3.17.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting typing-extensions>=4.10.0 (from torch)\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting networkx (from torch)\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in /Users/diemvs/Documents/GitHub/ml-dev-ops/.venv/lib/python3.13/site-packages (from torch) (3.1.5)\n",
      "Collecting fsspec (from torch)\n",
      "  Using cached fsspec-2025.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting setuptools (from torch)\n",
      "  Using cached setuptools-75.8.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting sympy==1.13.1 (from torch)\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: numpy in /Users/diemvs/Documents/GitHub/ml-dev-ops/.venv/lib/python3.13/site-packages (from torchvision) (2.2.3)\n",
      "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision)\n",
      "  Using cached pillow-11.1.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (9.1 kB)\n",
      "Collecting protobuf>=3.20.2 (from onnx)\n",
      "  Using cached protobuf-5.29.3-cp38-abi3-macosx_10_9_universal2.whl.metadata (592 bytes)\n",
      "Collecting coloredlogs (from onnxruntime)\n",
      "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime)\n",
      "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Requirement already satisfied: packaging in /Users/diemvs/Documents/GitHub/ml-dev-ops/.venv/lib/python3.13/site-packages (from onnxruntime) (24.2)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
      "  Using cached humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/diemvs/Documents/GitHub/ml-dev-ops/.venv/lib/python3.13/site-packages (from jinja2->torch) (3.0.2)\n",
      "Downloading torch-2.6.0-cp313-none-macosx_11_0_arm64.whl (66.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hUsing cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Downloading torchvision-0.21.0-cp313-cp313-macosx_11_0_arm64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading onnxruntime-1.20.1-cp313-cp313-macosx_13_0_universal2.whl (31.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.0/31.0 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached pillow-11.1.0-cp313-cp313-macosx_11_0_arm64.whl (3.1 MB)\n",
      "Using cached protobuf-5.29.3-cp38-abi3-macosx_10_9_universal2.whl (417 kB)\n",
      "Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Using cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Using cached filelock-3.17.0-py3-none-any.whl (16 kB)\n",
      "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Using cached fsspec-2025.2.0-py3-none-any.whl (184 kB)\n",
      "Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Using cached setuptools-75.8.0-py3-none-any.whl (1.2 MB)\n",
      "Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Building wheels for collected packages: onnx\n",
      "  Building wheel for onnx (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for onnx: filename=onnx-1.17.0-cp313-cp313-macosx_14_0_arm64.whl size=14911911 sha256=7a4b5078cbcab67439a89857fb7927557cf90680f8db2634a79540de1a79e505\n",
      "  Stored in directory: /Users/diemvs/Library/Caches/pip/wheels/ac/c1/73/4fa9bcde707160b22aa12f1d86d447ee5de075399d45f566e9\n",
      "Successfully built onnx\n",
      "Installing collected packages: mpmath, flatbuffers, typing-extensions, sympy, setuptools, protobuf, pillow, networkx, humanfriendly, fsspec, filelock, torch, onnx, coloredlogs, torchvision, onnxruntime\n",
      "Successfully installed coloredlogs-15.0.1 filelock-3.17.0 flatbuffers-25.2.10 fsspec-2025.2.0 humanfriendly-10.0 mpmath-1.3.0 networkx-3.4.2 onnx-1.17.0 onnxruntime-1.20.1 pillow-11.1.0 protobuf-5.29.3 setuptools-75.8.0 sympy-1.13.1 torch-2.6.0 torchvision-0.21.0 typing-extensions-4.12.2\n"
     ]
    }
   ],
   "source": [
    "! pip install torch torchvision onnx onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n",
      "100.0%\n",
      "100.0%\n",
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 0.4725\n",
      "Epoch [2/5], Loss: 0.2371\n",
      "Epoch [3/5], Loss: 0.0780\n",
      "Epoch [4/5], Loss: 0.2122\n",
      "Epoch [5/5], Loss: 0.3836\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Гиперпараметры\n",
    "batch_size = 64\n",
    "learning_rate = 0.01\n",
    "epochs = 5\n",
    "\n",
    "# Загрузка данных\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Определение модели\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)  # Разворачиваем изображение\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Создание модели и оптимизатора\n",
    "model = SimpleNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Обучение модели\n",
    "for epoch in range(epochs):\n",
    "    for images, labels in trainloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Сохранение обученной модели\n",
    "torch.save(model.state_dict(), \"mnist_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель успешно экспортирована в ONNX.\n"
     ]
    }
   ],
   "source": [
    "dummy_input = torch.randn(1, 1, 28, 28) \n",
    "torch.onnx.export(model, dummy_input, \"mnist_model.onnx\", input_names=[\"input\"], output_names=[\"output\"])\n",
    "print(\"Модель успешно экспортирована в ONNX.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Выход модели: [array([[-221.3485  ,  -53.577065,  -13.014393,   87.604065, -140.17885 ,\n",
      "         -14.636501, -195.58873 ,  -11.833436,  -76.045074,  -57.548992]],\n",
      "      dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Загрузим ONNX-модель\n",
    "session = ort.InferenceSession(\"mnist_model.onnx\")\n",
    "\n",
    "# Тестовый ввод\n",
    "dummy_input = torch.randn(1, 1, 28, 28).numpy()\n",
    "\n",
    "# Запуск предсказания\n",
    "outputs = session.run(None, {\"input\": dummy_input})\n",
    "print(\"Выход модели:\", outputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
